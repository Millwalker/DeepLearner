{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f819a69e-72a2-4f06-8d14-ee7fddde06e8",
   "metadata": {},
   "source": [
    "<center><h1>Challenge RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb3b385-0c22-44fe-ab9c-c828b0fe697c",
   "metadata": {},
   "source": [
    "In this challenge, the gaol is to train a classifier for sequences of genetic code.\n",
    "\n",
    "Each sequence is represented by a string of letters [‘A’, ‘C’, ‘G’, ’T’] and belongs to one of five categories/classes labelled [0,…,4].\n",
    "\n",
    "For training purposes, you will find 400 labelled sequences, each of length 400 characters (sequences: **data_x**, labels: **data_y**).\n",
    "\n",
    "To validate your model, you have a further 100 labelled sequences (**val_x**, **val_y**) with 1200 characters each.\n",
    "\n",
    "Finally, you have 250 unlabeled sequences (**test_x**, 2000 characters) which need to be classified.\n",
    "\n",
    "Hint: Training recurrent networks is very expensive! Do not start working on this challenge too late or you might not manage to finish in time.\n",
    "\n",
    "Your task is to train an RNN-based classifier and make a prediction for the missing labels of the test set (**test_x** in the attached archive). Store your prediction as a one-dimensional **numpy.ndarray**, save this array as **prediction.npy**, and upload this file to the whiteboard.\n",
    "\n",
    "To load  the data and save your prediction, please refer to the following code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "474982fa-abc6-4b0c-9446-69fa78600c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,) <U400\n",
      "(400,) int64\n",
      "(100,) <U1200\n",
      "(100,) int64\n",
      "(250,) <U2000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open('rnn-challenge-data.npz', 'rb') as f:\n",
    "    X = np.load(f)\n",
    "    data_x = X['data_x']\n",
    "    data_y = X['data_y']\n",
    "    val_x = X['val_x']\n",
    "    val_y = X['val_y']\n",
    "    test_x = X['test_x']\n",
    "\n",
    "# TRAINING DATA: INPUT (x) AND OUTPUT (y)\n",
    "print(data_x.shape, data_x.dtype)\n",
    "print(data_y.shape, data_y.dtype)\n",
    "\n",
    "# VALIDATION DATA: INPUT (x) AND OUTPUT (y)\n",
    "print(val_x.shape, val_x.dtype)\n",
    "print(val_y.shape, val_y.dtype)\n",
    "\n",
    "# TEST DATA: INPUT (x) ONLY\n",
    "print(test_x.shape, test_x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21c1adeb-1a35-4b26-81d0-963c91be821d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTAGCTGAGCTACTGAGCTACAGTTGACTGACCAGTCAGTGCTAGCTACTGACAGTCTGACAGTTGACCTGACTGATGACCAGTCTAGCAGTGCTACTAGCTAGGCTACAGTCAGTTGACCAGTCTGACAGTCAGTCTGACTGACAGTCAGTCTAGGCTATGACCTGACTGATGACCTGACTGACTGACAGTCTGACTGATGACGCTATGACCTGACTAGCTAGCAGTTGACTGACCTGACAGTGCTACTAGCAGTTGACCAGTGCTACAGTCTGATGACTGACCTGACAGTCTAGGCTACAGTTGACCTGACAGTCAGTGCTACTGACAGTCTAGTGACCAGTCAGTCAGTTGACCTGACTAGCAGTTGACGCTATGACCAGTCTGACAGTGCTACTAG\n"
     ]
    }
   ],
   "source": [
    "# Printing one for having an idea\n",
    "print(data_x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6cb7d5-25c9-46cd-872e-04b33d98025f",
   "metadata": {},
   "source": [
    "# Code\n",
    "We could try\n",
    "* Simple RNN\n",
    "* LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "509aff0c-e2b2-4d89-a412-357684ff0b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e850389-4d8c-4161-bb26-bd82d9795df0",
   "metadata": {},
   "source": [
    "Here making us of this tutorial : [NLP From Scratch: Classifying Names with a Character level RNN](https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html) (from Pytorch)\n",
    "\n",
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94b13b18-8d09-4864-b5dc-73831d6fa6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_categories = 5              # [0, 1, 2, 3, 4]\n",
    "\n",
    "all_letters = 'ACGT'          # rather than all possible letters through 'string.ascii'\n",
    "n_letters = len(all_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da36cca8-7fa4-448a-a3a9-20441bd470af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0.]])\n",
      "torch.Size([8, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "# Find letter index from all_letters, e.g. \"a\" = 0\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# Turn a line into a <line_length x 1 x n_letters>,\n",
    "# or an array of one-hot letter vectors\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# Testing that everything works\n",
    "print(letterToTensor('A'))\n",
    "print(lineToTensor('ACGTTAGC').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7898b9ac-d574-4964-9d8e-b36723c81aa2",
   "metadata": {},
   "source": [
    "Turning all the data to tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ff606a4-a9ad-4a6c-89eb-d75529e25c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x_torch = torch.stack([lineToTensor(data_x[i]) for i in range(len(data_x))])\n",
    "val_x_torch = torch.stack([lineToTensor(val_x[i]) for i in range(len(val_x))])\n",
    "test_x_torch = torch.stack([lineToTensor(test_x[i]) for i in range(len(test_x))])\n",
    "\n",
    "data_y_torch = torch.from_numpy(data_y)\n",
    "val_y_torch = torch.from_numpy(val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b642e58-3135-4100-afb7-01090cfcf3ed",
   "metadata": {},
   "source": [
    "## Creating the model\n",
    "\n",
    "What is `n_hidden` useful for? Is it how large is the network at its hidden layer part?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "14a27ca6-f80b-4aed-961c-96cdd220e146",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "n_hidden = 128\n",
    "rnn = RNN(n_letters, n_hidden, n_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588c37ed-470a-411c-8065-7539f14e0781",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f6f4fab6-4f99-4e25-b627-1e651fe7d93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6499, -1.6228, -1.6302, -1.6709, -1.4845]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Trying with a single letter\n",
    "input = letterToTensor('A')\n",
    "hidden = torch.zeros(1, n_hidden)\n",
    "\n",
    "output, next_hidden = rnn(input, hidden)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "25b5b26f-0158-41a6-b43b-0e3afbf2ec67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5788, -1.5087, -1.6327, -1.6571, -1.6793]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Trying with a sequence\n",
    "input = data_x_torch[0] # first sequence of the training data\n",
    "hidden = torch.zeros(1, n_hidden)\n",
    "\n",
    "output, next_hidden = rnn(input[0], hidden)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5b98d003-d63e-4a15-bea8-0c69ebf0987d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Helper function for classification\n",
    "def categoryFromOutput(output):\n",
    "    _, top_i = output.topk(1)\n",
    "    return top_i[0].item()\n",
    "\n",
    "print(categoryFromOutput(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8c57886d-2e6a-4594-a37d-95ea3d65fd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "learning_rate = 0.001 # If you set this too high, it might explode. If too low, it might not learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef47b201-b380-4661-96b2-352ca2b9159f",
   "metadata": {},
   "source": [
    "Here we try to implement now the **teacher forcing** in the training phase. Question: shall the teacher forcing be at a character level or at word level?\n",
    "\n",
    "First we try at a character level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "378fddb9-db3f-4a3e-8a4f-39cb1c1300c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5                # 0 = always teacher forcing, 1 = no teacher forcing\n",
    "\n",
    "def train(category_tensor, line_tensor):\n",
    "    hidden = rnn.initHidden().to(device)\n",
    "\n",
    "    rnn.zero_grad()       # Set all gradients of model to zero\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "#         use_teacher_forcing = True if np.random.random()<0.5 else False\n",
    "        \n",
    "#         if use_teacher_forcing:\n",
    "#             # Rewire\n",
    "#         else:\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "    \n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "\n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef039d7c-18eb-4b1e-8ebb-ce21021f3def",
   "metadata": {},
   "source": [
    "### Using GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4fe1bf91-4889-4636-9659-b0c3e957e013",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(device) # Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "rnn.to(device); # This sends the whole network parameters and buffers to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3f409b6a-1468-458c-b338-0a2c8485a373",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "164c614e8734425591767a36a64213d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch n°1: Loss = 1.61437704205513\n",
      "Epoch n°2: Loss = 1.6020556017756462\n",
      "Epoch n°3: Loss = 1.5899737989902496\n",
      "Epoch n°4: Loss = 1.577837836444378\n",
      "Epoch n°5: Loss = 1.5653494307398796\n",
      "Epoch n°6: Loss = 1.5521654406189918\n",
      "Epoch n°7: Loss = 1.537831297814846\n",
      "Epoch n°8: Loss = 1.5216340273618698\n",
      "Epoch n°9: Loss = 1.5021603354811668\n",
      "Epoch n°10: Loss = 1.4750711503624916\n",
      "Epoch n°11: Loss = nan\n",
      "Stopping at epoch n°11: loss is nan\n"
     ]
    }
   ],
   "source": [
    "# n_iters = 100000\n",
    "epochs = 13\n",
    "# print_every = 5000\n",
    "# plot_every = 1000\n",
    "\n",
    "\n",
    "\n",
    "# Keep track of losses for plotting\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "# def timeSince(since):\n",
    "#     now = time.time()\n",
    "#     s = now - since\n",
    "#     m = math.floor(s / 60)\n",
    "#     s -= m * 60\n",
    "#     return '%dm %ds' % (m, s)\n",
    "\n",
    "# start = time.time()\n",
    "\n",
    "# train_ds = torch.utils.data.TensorDataset(data_x_torch, data_y_torch)\n",
    "# train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "    \n",
    "#     output, loss = train(category_tensor, line_tensor)\n",
    "#     current_loss += loss\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    current_loss = 0\n",
    "    \n",
    "    # Goes through the whole dataset:\n",
    "    for category, line_tensor in zip(data_y, data_x_torch):\n",
    "        \n",
    "        # For using GPU; doesn't seem to be speeding-up though\n",
    "        input = line_tensor.to(device)\n",
    "        label = torch.tensor([category]).to(device)\n",
    "        \n",
    "        output, loss = train(label, input)\n",
    "        current_loss += loss\n",
    "    \n",
    "    print(f\"Epoch n°{epoch}: Loss = {current_loss/400}\")\n",
    "    all_losses.append(current_loss / 400)\n",
    "    \n",
    "    # Break the loop if reached a \"nan\", more computing would be unnecessary\n",
    "    if np.isnan(all_losses[-1]):\n",
    "        print(f\"Stopping at epoch n°{epoch}: loss is nan\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "42d5518c-d08d-4dc6-b41b-93b39742d654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the loss\n",
    "plt.plot(all_losses)\n",
    "plt.xlabel(\"Epochs\");\n",
    "plt.ylabel(\"Loss\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f8984d-2d06-4c5c-bd9e-f420359673e0",
   "metadata": {},
   "source": [
    "# Validation\n",
    "\n",
    "We want to see what is our score on the validation set **val_x** with **val_y**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0bc5b90e-cca2-425e-bf52-c1eb7805b0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan, nan, nan, nan]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "Label for this data: 4\n"
     ]
    }
   ],
   "source": [
    "# Trying to produce 1 prediction\n",
    "i = 0\n",
    "category = val_y_torch[i]\n",
    "line_tensor = val_x_torch[i]\n",
    "\n",
    "input = val_x_torch[0].to(device) # first sequence of the training data\n",
    "hidden = torch.zeros(1, n_hidden).to(device)\n",
    "\n",
    "output, next_hidden = rnn(input[0], hidden)\n",
    "print(output)\n",
    "print(f\"Label for this data: {category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9643c431-072b-4429-ac04-74988d2ab305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then trying to loop and produce all submission for giving a score:\n",
    "for ... in ...:\n",
    "    \n",
    "print(f\"Score over validation dataset: {score:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172cc91d-3d94-49d5-9387-9e3f6f8025b5",
   "metadata": {},
   "source": [
    "# Prediction and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03833523-d7f2-49b4-be57-6ba76002c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE SURE THAT YOU HAVE THE RIGHT FORMAT\n",
    "assert prediction.ndim == 1\n",
    "assert prediction.shape[0] == 250\n",
    "\n",
    "# AND SAVE EXACTLY AS SHOWN BELOW\n",
    "np.save('prediction.npy', prediction.astype(int))\n",
    "\n",
    "# MAKE SURE THAT THE FILE HAS THE CORRECT FORMAT\n",
    "def validate_prediction_format():\n",
    "    loaded = np.load('prediction.npy')\n",
    "    assert loaded.shape == (250, )\n",
    "    assert loaded.dtype == int\n",
    "    assert (loaded <= 4).all()\n",
    "    assert (loaded >= 0).all()\n",
    "validate_prediction_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20e2910-300b-439f-bb5d-65752dfcf1bc",
   "metadata": {},
   "source": [
    "**accuracy** → **points**<br>\n",
    "≥95% → 10<br>\n",
    "≥90% → 7<br>\n",
    "≥85% → 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLenv",
   "language": "python",
   "name": "dlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
